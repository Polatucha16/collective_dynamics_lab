{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ce08b2-a012-478a-ad3d-9c41abccee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d58ee-6beb-42fc-9c90-855018b3f551",
   "metadata": {},
   "source": [
    "#### data names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "431f60b8-233f-4eeb-80b7-f39593b7aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=False,    #True if not dowloaded\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=False,    #True if not dowloaded\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e87aef-6b9f-4977-a89b-7b41fbed73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697d16d-ee2e-4e09-a598-08ea2b15bcd8",
   "metadata": {},
   "source": [
    "#### Define NN part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562df124-5701-493f-9dba-0e7d347b5908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "from torch import nn\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        # call __init__ from the parent class: nn.Module.\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        # this flattens the images in the batch to the 1d tensors suitabe for nn.Sequential\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 16),  #  input -> 1st layer  = first hidden layer  16 neurons. (like matrix of shape: 16 x 784)\n",
    "            nn.ReLU(),             # ReLU activation funtion at 16 neurons of the 1st layer\n",
    "            nn.Linear(16, 16),     # 1st layer -> 2nd layer = second hidden layer with 16 neurons\n",
    "            nn.ReLU(),             # ReLU activation funtion at 16 neurons of the 2nd layer\n",
    "            nn.Linear(16, 10),     # 2nd layer -> output \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X, y = batch[0].to(device), batch[1].to(device)\n",
    "        pred = model(X)            #*mat: evaluate the model batch_size of times and put results in a tensor \"next\" to each other\n",
    "        loss = loss_fn(pred, y)    #*mat: compute the loss function \n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()      # place in memory for the derivative needs reseting\n",
    "        loss.backward()            #*mat: calculate the derivative (**)\n",
    "        optimizer.step()           # call the black box algoritm that do the magic\n",
    "\n",
    "        # print the progress every 100th batch.\n",
    "        if i % 100 == 0:\n",
    "            loss, current = loss.item(), i * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X, y = batch[0].to(device), batch[1].to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f2edb-c084-4444-83eb-a035fb8f4f79",
   "metadata": {},
   "source": [
    "#### train-y part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "11124499-ba51-4ebb-a266-31645f82cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 1e-2\n",
    "batch_size = 100\n",
    "epochs = 5\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = NeuralNetwork().to(device) \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "228d7fb4-2b65-40e0-8ea1-716ab9f0adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=100, shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=100, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d34ad219-8858-45ea-b729-b30379c21447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.334503  [    0/60000]\n",
      "loss: 1.439916  [10000/60000]\n",
      "loss: 0.548414  [20000/60000]\n",
      "loss: 0.410761  [30000/60000]\n",
      "loss: 0.493014  [40000/60000]\n",
      "loss: 0.328411  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.331461 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.287031  [    0/60000]\n",
      "loss: 0.325892  [10000/60000]\n",
      "loss: 0.206460  [20000/60000]\n",
      "loss: 0.506496  [30000/60000]\n",
      "loss: 0.300466  [40000/60000]\n",
      "loss: 0.281228  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.278768 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.249926  [    0/60000]\n",
      "loss: 0.329086  [10000/60000]\n",
      "loss: 0.113245  [20000/60000]\n",
      "loss: 0.296915  [30000/60000]\n",
      "loss: 0.298392  [40000/60000]\n",
      "loss: 0.205776  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.248103 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.164818  [    0/60000]\n",
      "loss: 0.275655  [10000/60000]\n",
      "loss: 0.424604  [20000/60000]\n",
      "loss: 0.186129  [30000/60000]\n",
      "loss: 0.234268  [40000/60000]\n",
      "loss: 0.309248  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.212525 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.236029  [    0/60000]\n",
      "loss: 0.174242  [10000/60000]\n",
      "loss: 0.295013  [20000/60000]\n",
      "loss: 0.209774  [30000/60000]\n",
      "loss: 0.153248  [40000/60000]\n",
      "loss: 0.199949  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.202075 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "abc984de-7074-4aa1-8fb9-996ff25dcd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2.3483,  -3.7659,   2.1727,   5.7998, -10.4997,   2.7526,  -3.3734,\n",
      "         -10.7476,   6.2890,  -4.6178]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# result for random image\n",
    "X = torch.rand(1, 28, 28, device=device) # random image\n",
    "print(model(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2eb5d5f9-26c5-4fb0-9ea9-2caf30de46d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5025, -1.7869, -1.8945,  0.0168, -6.9241,  2.1257, -2.2416, -7.7897,\n",
      "         12.7867,  0.1850]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ith = 777\n",
    "img, label = training_data[ith]\n",
    "print(model(img.to(device)))\n",
    "print(label)\n",
    "fig = plt.figure(figsize=(5, 10))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(X.to('cpu').squeeze(), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "60cf626d-40c3-41df-9ac3-e5d13bbb1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At 0    NN has     2.35\n",
      " At 1    NN has    -3.77\n",
      " At 2    NN has     2.17\n",
      " At 3    NN has     5.80\n",
      " At 4    NN has   -10.50\n",
      " At 5    NN has     2.75\n",
      " At 6    NN has    -3.37\n",
      " At 7    NN has   -10.75\n",
      " At 8    NN has     6.29\n",
      " At 9    NN has    -4.62\n"
     ]
    }
   ],
   "source": [
    "# random pic X\n",
    "for i,x in enumerate(model(X)[0]):\n",
    "    print(f\" At {i:<4} NN has {x.item():>8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3d4113a2-b4bb-4df4-8e21-c194ed2ee5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At 0    NN has    -1.50\n",
      " At 1    NN has    -1.79\n",
      " At 2    NN has    -1.89\n",
      " At 3    NN has     0.02\n",
      " At 4    NN has    -6.92\n",
      " At 5    NN has     2.13\n",
      " At 6    NN has    -2.24\n",
      " At 7    NN has    -7.79\n",
      " At 8    NN has    12.79\n",
      " At 9    NN has     0.18\n"
     ]
    }
   ],
   "source": [
    "img777, label = training_data[777]\n",
    "for i,x in enumerate(model(img777.to(device))[0]):\n",
    "    print(f\" At {i:<4} NN has {x.item():>8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af9a0ec-090f-42d7-b4bb-0d0b6c022858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
